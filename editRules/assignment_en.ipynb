{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit rules for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "During the theory lectures, the theory behind edit rules is explained in detail.\n",
    "During this assignment, you will use edit rules for categorical data in a practical fashion.\n",
    "More specifically, you will use edit rules based on a small dataset that captures data about clinical trials.\n",
    "This dataset is composed by combining attributes from two different sources, being [EudraCT](https://eudract.ema.europa.eu/) and [ClinicalTrials.gov](https://clinicaltrials.gov/).\n",
    "You will have to detect inconsistencies between these sources by means of the Fellegi-Holt framework.\n",
    "Later during this course, methods are introduced to fix these inconsistencies by means of imputation.\n",
    "\n",
    "Before you can start with detecting inconsistencies, we will introduce the pandas library, which offers a variety of functions for processing and analyzing data, which will be used during the remainder of this assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The pandas library\n",
    "\n",
    "During this assignment, you will extensively use the [pandas](https://pandas.pydata.org/) library in Pyhton.\n",
    "This library is mainly used for reading, processing and analyzing datasets.\n",
    "To get familiar with this library, you will start with some pandas-based exercises.\n",
    "By means of these exercises, you will also get familiar with the given dataset (clinical_trials.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Read the 'clinical_trials.csv' dataset by means of the pandas library\n",
    "dataset = #..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that it is straightforward to read a .csv file by means of the pandas library.\n",
    "When you do this, a pandas DataFrame object is created that represents a table with rows and attributes matching respectively the rows and columns of the given .csv file.\n",
    "In the following, we will look into this DataFrame object in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: count the number of rows and columns in the DataFrame object\n",
    "number_of_rows = #...\n",
    "print(\"Number of rows: {:d}\".format(number_of_rows))\n",
    "\n",
    "number_of_columns = #...\n",
    "print(\"Number of columns: {:d}\".format(number_of_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know which values and columns are persisted in the dataset, it is possible to look into a sample (first rows) of the dataset.\n",
    "Besides that, it is also possible to retrieve, for each column separately, which values are persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print the first ten rows of the dataset\n",
    "print(\"First ten rows of the dataset: \")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print, for each column, the name of the column and a set of unique values that are persisted for this column\n",
    "print(\"All columns and column values: \")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have managed to complete the previous exercise successfully, you can see that the dataset consists of 4 columns: 'open', 'double_blind', 'single_blind' and 'masking'.\n",
    "The first three columns contain boolean values which are collected from the [EudraCT](https://eudract.ema.europa.eu/) dataset and the values in the column 'masking' are collected from the [ClinicalTrials.gov](https://clinicaltrials.gov/) dataset.\n",
    "Each row specifies details related to the design of a clinical trial that is persisted in both datasets.\n",
    "\n",
    "Before continuing, an overview is given of the semantical meaning of the different columns.\n",
    "\n",
    "* **open**: a study in which both the participants and the researchers know which treatment is given;\n",
    "* **single_blind**: a study in which only one of both parties (mostly the researchers) know which treatment is given;\n",
    "* **double_blind**: a study in which none of the parties know which treatment is given;\n",
    "* **masking**: categorical attribute containing values related to the masking/blindness of clinical trials (0 = Open, 1 = Single, 2 = Double, >2 = Triple/Quadruple).\n",
    "\n",
    "Besides that, each column can contain a special value: NaN.\n",
    "This value represents a `null`-value and indicates that certain data is not known.\n",
    "The more `null`-values appear, the less accurate certain analysis based on this data will reflect the reality, which is obviously harmful for a researcher.\n",
    "During the next exercises, you will assess how many column values and rows contain `null` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: count the total number of column values (cells) that contain a null-value\n",
    "print(\"Number of null-values:\")\n",
    "# ...\n",
    "# 5202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: count the total number of rows that contain a null-value\n",
    "print(\"Number of rows containing a null-value:\")\n",
    "# ...\n",
    "# 2083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print, for each column separately, the total number of null-values\n",
    "print(\"Number of null-values per attribute:\")\n",
    "# ...\n",
    "# 1547,1622,1779,254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is also possible to select certain columns and rows that satisfy given criteria in order to find data more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print, for the first 10 rows, the values of column 'open'\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print, for the first 10 rows, the values of columns 2 to 4\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print the content of the row with index 1000\n",
    "# ...\n",
    "# open            Yes\n",
    "# double_blind     No\n",
    "# single_blind     No\n",
    "# masking           0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print the content of the first 10 rows in which column 'single_blind' contains the value 'Yes'\n",
    "# ...\n",
    "# rijen 8, 15, 24, 30, 32, 33, 54, 62, 88, 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: count the total number of rows in which column 'single_blind' contains the value 'Yes' and column 'masking' contains the value '1'\n",
    "# ...\n",
    "# 287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: print the content of the first 10 rows that do NOT contain null-values\n",
    "# ...\n",
    "# 1, 2, 3, 4, 5, 7, 8, 9, 11, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Edit rules\n",
    "\n",
    "Now you have practiced with the [pandas](https://pandas.pydata.org/) library in Python and investigated the dataset that we are going to use during this assigment, it is time to assess the quality of this dataset and to enhance this quality by means of data quality rules.\n",
    "As we mentioned before, the dataset captures clinical trial design data extracted from two different data sources.\n",
    "In the remainder, you will investigate how consistent this data is within (intra-consistency) and between (inter-consistency) these two different sources.\n",
    "\n",
    "The basic principle that we are going to apply to assess the quality of a dataset (or part of a dataset) by means of a rule-based approach is the following.\n",
    "* First, a set of quality rules is constructed that must be satisfied by each object (row) in the dataset.\n",
    "In our case, these rules define constraints on attribute values or on combinations of attribute values in the dataset.\n",
    "* Satisfaction of each quality rule is tested by each data object and results in a boolean value ('yes, the object satisfies the rule' or 'no, the object does not satisfy the rule').\n",
    "* The more rules that are satisfied by a data object, the higher the quality of the data object is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definition\n",
    "\n",
    "In this section, we will fill in this basic principle by means of *edit rules* on data objects (rows) of the given dataset.\n",
    "Edit rules are introduced by Fellegi & Holt in their research paper: A Systematic Approach to Automatic Edit and Imputation (1976) and form an elegant way to represent non-permissible combinations of values. \n",
    "\n",
    "The general definition of an edit rule is the following.\n",
    "An *edit rule* over a dataset $R$ with attributes $a_1,\\dots,a_k$ is a rule of type $E_1 \\times \\dots \\times E_k$ in which each $E_i$ is a non-empty subset of $A_i$ (with $A_i$ the domain of attribute $a_i$, without `null`-values!).\n",
    "An edit rule semantically defines a set of non-permissible rows within $A_1 \\times \\dots \\times A_k$.\n",
    "When a row is part of this set, it does **not** satisfy (or it fails) the edit rule.\n",
    "In any other case, it does.\n",
    "\n",
    "We already have defined a set of eight edit rules on our dataset.\n",
    "These can be found in the following table.\n",
    "\n",
    "| Rule  | open      | single_blind | double_blind | masking      |\n",
    "|-------|-----------|--------------|--------------|--------------|\n",
    "| 1     | Yes       | dom(single)  | Yes          | dom(masking) |\n",
    "| 2     | dom(open) | Yes          | Yes          | dom(masking) |\n",
    "| 3     | Yes       | Yes          | dom(double)  | dom(masking) |\n",
    "| 4     | dom(open) | No           | dom(double)  | 1            |\n",
    "| 5     | dom(open) | dom(single)  | No           | 2            |\n",
    "| 6     | dom(open) | dom(single)  | Yes          | 0            |\n",
    "| 7     | dom(open) | Yes          | dom(double)  | 0            |\n",
    "| 8     | dom(open) | dom(single)  | Yes          | 1            |\n",
    "\n",
    "As an example, we will investigate edit rule 1 ({Yes} $\\times$ dom(single) $\\times$ {Yes} $\\times$ dom(masking)) together.\n",
    "This rule states that *open* = 'Yes' and *double_blind* = 'Yes' may **not** appear together, independent of the value of the other two attributes (dom($a_i$) represents the entire domain of attribute $a_i$).\n",
    "We also say that attributes *open* and *double_blind* enter in edit rule 1, because the value sets for these attributes are a real subset of the domain of the attributes.\n",
    "Semantically, this edit rule makes sense, because it is not permitted that a study is both 'open' and 'double_blind'.\n",
    "Before continuing, try to investigate the other edit rules by interpreting them semantically.\n",
    "Also, list for each edit rule which attributes are entering.\n",
    "Make sure to understand the definition of edit rules well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: count the number of rows from the given dataset that fail edit rule 1 given in the table above.\n",
    "failing_rows = # ...\n",
    "print(\"Number of rows failing edit rule 1: {:d}\".format(failing_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following piece of code, we already initialized the given eight edit rules for you, which you will need during the remainder of the assignment.\n",
    "If an attribute is not listed in an edit rule, it does not enter in the edit rule and has no influence on satisfaction of the rule.\n",
    "Before continuing, think about why this last statement is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_rules = [\n",
    "                {\n",
    "                    'open' : 'Yes',\n",
    "                    'double_blind' : 'Yes'\n",
    "                },\n",
    "                {\n",
    "                    'single_blind' : 'Yes',\n",
    "                    'double_blind' : 'Yes'\n",
    "                },\n",
    "                {\n",
    "                    'open' : 'Yes',\n",
    "                    'single_blind' : 'Yes'\n",
    "                }, \n",
    "                {\n",
    "                    'single_blind' : 'No',\n",
    "                    'masking' : '1'\n",
    "                },\n",
    "                {\n",
    "                    'double_blind' : 'No',\n",
    "                    'masking' : '2'\n",
    "                },\n",
    "                {\n",
    "                    'double_blind' : 'Yes',\n",
    "                    'masking' : '0'\n",
    "                },\n",
    "                {\n",
    "                    'single_blind' : 'Yes',\n",
    "                    'masking' : '0'\n",
    "                },\n",
    "                {\n",
    "                    'double_blind' : 'Yes',\n",
    "                    'masking' : '1'\n",
    "                }\n",
    "             ]\n",
    "\n",
    "print(\"Edit rules: \")\n",
    "for edit_rule in edit_rules:\n",
    "    print(edit_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: implement an algorithm that persists, per row number, the edit rules that are failed by the corresponding row in the violations dictionary-object.\n",
    "# Do not persist rows that satisfy all edit rules.\n",
    "# The edit rules may be represented by their index in the Python-list edit_rules\n",
    "\n",
    "def get_violated_rows(dataset, edit_rules):\n",
    "    violations = {}\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # debug info\n",
    "        if index % 5000 == 0:\n",
    "            print(str(index) + \" rows processed\")\n",
    "            \n",
    "        # TO IMPLEMENT...\n",
    "            \n",
    "    return violations\n",
    "\n",
    "violations = get_violated_rows(dataset, edit_rules)\n",
    "print(\"number of violated rows: {:d}\".format(len(violations.keys())))\n",
    "\n",
    "# 1222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: validate for the first row persisted in the violations dictionary whether your algorithm gives a correct result\n",
    "row = next(iter(violations))\n",
    "print(dataset.iloc[row])\n",
    "\n",
    "for edit_rule_index in violations[row]:\n",
    "    print(edit_rules[edit_rule_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Complete set van edit regels\n",
    "\n",
    "In the previous section, we tested which rows in the dataset fail the given set of edit rules.\n",
    "In this section, we will investigate which attributes potentially contain errors within these failing rows such that we can adapt this value later.\n",
    "\n",
    "It is straightforward to see that a row can only satisfy a failing edit rule if the value of an attribute that enters in the edit rule is adapted.\n",
    "\n",
    "As an example, take the following row.\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| Yes       | No           | Yes          | 2            |\n",
    "\n",
    "This row violates edit rule 1: {Yes} $\\times$ dom(single) $\\times$ {Yes} $\\times$ dom(masking) and attributes *open* and *double_blind* enter in this edit rule, because the value sets of these attributes are real subsets of their domains.\n",
    "In order to make this row satisfy edit rule 1, it is necessary to adapt the value of attribute *open* or attribute *double_blind*.\n",
    "Adaptation of the values of attributes *single_blind* or *masking* does not influence satisfaction of this edit rule.\n",
    "\n",
    "If we choose to adapt the value of attribute 'open' to 'No' (the only remaining value within the domain), we can construct the following row.\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| No        | No           | Yes          | 2            |\n",
    "\n",
    "It is clear that this row satisfies edit rule 1.\n",
    "Moreover, all other edit rules are also satisfied by this row (check this).\n",
    "\n",
    "Suppose now that we choose to adapt the value of attribute 'double_blind' to 'No' in the original row.\n",
    "As a result, we can construct the following row.\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| Yes       | No           | No           | 2            |\n",
    "\n",
    "This row also satisfies edit rule 1.\n",
    "However, if we check this row against the other edit rules, we can see that this row does NOT satisfy edit rule 5: dom(open) $\\times$ dom(single) $\\times$ {No} $\\times$ {2}.\n",
    "This, again, gives a problem.\n",
    "\n",
    "The reason that this happens is because edit rules 1 and 5 are not fully independent from each other.\n",
    "Indeed, edit rule 1 states that *open* = 'Yes' and *double_blind* = 'Yes' cannot appear together in a row, and therefore, *open* = 'Yes' can only appear together with *double_blind* = 'No'.\n",
    "Besides that, edit rule 5 states that *double_blind* = 'No' and *masking* = '2' cannot appear together in a row.\n",
    "Both statements imply, thus, that *open* = 'Yes' may not appear together with *masking* = '2'.\n",
    "We can now construct an *implied* edit rule, given these two edit rules, with the form {Yes} $\\times$ dom(single) $\\times$ dom(double) $\\times$ {2}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, we can define the implication procedure as follows.\n",
    "\n",
    "Consider a set $\\mathcal{E}_c$ consisting of at least two edit rules (which we will call the *contributing set*) and an attribute $a_g$ (which we will call the *generator*).\n",
    "An edit rule $E_1^* \\times \\cdots \\times E_k^*$ consists of value sets $E_i^*$ for each attribute $a_i$, constructed by\n",
    "* taking the union of the values of the rules in $\\mathcal{E}_c$ for attribute $a_g$, and\n",
    "* taking the intersection of the values of the rules in $\\mathcal{E}_c$ for the other attributes.\n",
    "\n",
    "If no value set $E_i^*$ is empty, $E_1^* \\times \\cdots \\times E_k^*$ is called an *implied edit rule*.\n",
    "\n",
    "Besides that, if attribute $a_g$ enters in each edit rule in $\\mathcal{E}_c$, but it does not enter in the implied edit rule, we call the implied edit rule *essentially new*.\n",
    "\n",
    "The set of explicitly given edit rules together with all essentially new rules is called the *complete set* of edit rules.\n",
    "Fellegi & Holt have proven that the complete set of edit rules guarantees that each possible error can be localized correctly and the above situation cannot appear.\n",
    "\n",
    "Try to understand the definition of an implied edit rule, an essentially new edit rule and the complete set before continuing the assignment.\n",
    "Check whether the above example complies with this definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is clear that it is important to construct the complete set of edit rules in order to correctly identify attributes that are potentially in error.\n",
    "Try to construct the complete set of edit rules manually, starting from the explicit set given above, by applying the Field Code Forest algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exercise: try to construct, manually, by means of the Field Code Forest algorithm, all essentially new edit rules and add them to the given set (the first one is already given in the example above)\n",
    "\n",
    "edit_rules.append({'open' : 'Yes', 'masking' : '2'})\n",
    "#edit_rules.append(...)\n",
    "\n",
    "print(\"Edit rules: \")\n",
    "for edit_rule in edit_rules:\n",
    "    print(edit_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Persist, per row number, the edit rules that are failed by the corresponding row in the violations dictionary-object again.\n",
    "# Use the algorithm that you have implemented earlier.\n",
    "\n",
    "violations = get_violated_rows(dataset, edit_rules)\n",
    "print(\"number of violated rows: {:d}\".format(len(violations.keys())))\n",
    "# 1224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Foutlokalisatie\n",
    "\n",
    "Once the complete set of edit rules is generated and, for each row, the set of failing rules is identified, it is possible to correctly localize, for each failing row, the potential error.\n",
    "This can be done by identifying the minimal covering set of attributes for each row.\n",
    "\n",
    "A minimal covering set should meet two important properties.\n",
    "* The set is covering: each failing edit rule has at least 1 entering attribute in the set.\n",
    "This is straightforward, as we showed that we should adapt the value of at least 1 entering attribute in the edit rule to make the row satify this rule.\n",
    "* The set is minimal: if you remove an attribute from this set, the covering property is not met anymore.\n",
    "In other words, we want to adapt as few values as possible.\n",
    "\n",
    "Suppose the dataset contains the following row.\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| No        | Yes          | Yes          | 0            |\n",
    "\n",
    "In the original set of edit rules (so not the complete set), 3 failing edit rules are detected for this row, being\n",
    "\n",
    "| Rule | open      | single_blind | double_blind | masking      |\n",
    "|-------|-----------|--------------|--------------|--------------|\n",
    "| 2     | dom(open) | Yes          | Yes          | dom(masking) |\n",
    "| 6     | dom(open) | dom(single)  | Yes          | 0            |\n",
    "| 7     | dom(open) | Yes          | dom(double)  | 0            |\n",
    "\n",
    "The minimal sets of attributes covering these rules are {'single_blind', 'double_blind'}, {'single_blind', 'masking'} and {'double_blind', 'masking'}. \n",
    "Indeed, each failing rule has at least 1 entering attribute in these sets and the given sets are minimal (you cannot remove an attribute such that the set of attributes has still the covering property).\n",
    "From these minimal covering sets, we choose one that we are going to use to fix the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: implement an algorithm that tests, for each failing row, sets consisting of 1 attribute, then sets consisting of 2 attributes, and so on, until a minimal covering set is found.\n",
    "# Return, for each failing data object, one minimal covering set at random without taking into account the distributions.\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_minimal_covering_set(violated_rules):\n",
    "    #...\n",
    "    \n",
    "minimal_covering_sets = {}\n",
    "                \n",
    "for row in violations:\n",
    "    minimal_covering_sets[row] = get_minimal_covering_set(violations[row])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General note**\n",
    "\n",
    "It is possible (as shown in previous examples) that multiple minimal covering sets exist for a row.\n",
    "Strategies, most of them based on value distributions, exist to select (by probability) one minimal covering set for which the values should be adapted later.\n",
    "This, however, is out of scope of this course, but do not hesitate to think about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
